{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Netwrk from Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook I will be creating Neural Network from scratch. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First import numpy library. If it is not install then do `pip install numpy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets create a one hidden layer network having `n_x` input, `n_h` nodes in the hidden layer and 1 output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weight(n_x, n_h):\n",
    "    # weight of the w1 will be (n_h, n_x)\n",
    "    w1 = np.random.randn(n_h, n_x)*0.01\n",
    "    b1 = np.random.randn(n_h,1)*0.01\n",
    "    w2 = np.random.randn(1, n_h)*0.01\n",
    "    b2 = np.random.randn(1,1)*0.01 \n",
    "\n",
    "    parameters ={\n",
    "        \"w1\":w1,\n",
    "        \"b1\":b1,\n",
    "        \"w2\":w2,\n",
    "        \"b2\":b2\n",
    "    }\n",
    "\n",
    "    return parameters\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters = initialize_weight(n_x=3,n_h=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 3)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters['w1'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    output = 1/(1+np.exp(-1))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    output = np.maximum(0,x)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(X, parameters):\n",
    "    z1 = np.dot(parameters['w1'],X )+ parameters['b1']\n",
    "    a1 = relu(z1)\n",
    "    z2 = np.dot(parameters['w2'],a1) + parameters['b2']\n",
    "    a2 = sigmoid(z2) \n",
    "    return a2\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = initialize_weight(n_x=3,n_h=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.randn(3,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.7310585786300049)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward_pass(X= x , parameters= parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now lets do for `L` layer Deep Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights_deep(layer_list):\n",
    "\n",
    "    #layer list contain the info of neural network\n",
    "    #It can  be like [3,4,5,1]\n",
    "    #this means input is 3, there are two hidden layers with 4 and 5 nodes respectively and 1 output\n",
    "\n",
    "\n",
    "    parameters = {}\n",
    "    no_layers = len(layer_list)\n",
    "\n",
    "    for l in range(1,no_layers):\n",
    "        parameters[\"W\"+str(l)] = np.random.randn(layer_list[l], layer_list[l-1])*0.01\n",
    "        parameters[\"b\"+str(l)] = np.random.randn(layer_list[l],1)*0.01\n",
    "\n",
    "    return parameters\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_list = [3,4,5,5,1]\n",
    "parameters = initialize_weights_deep(layer_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'W1': array([[-0.00972737,  0.01119175, -0.00736359],\n",
       "        [ 0.01588215,  0.01012304, -0.0054073 ],\n",
       "        [ 0.00692811, -0.00561561, -0.00307239],\n",
       "        [-0.027928  , -0.00357822, -0.01049922]]),\n",
       " 'b1': array([[-0.0017814 ],\n",
       "        [-0.00871753],\n",
       "        [ 0.0091635 ],\n",
       "        [ 0.00148021]]),\n",
       " 'W2': array([[-1.32515262e-03,  1.30412169e-02,  2.94279776e-04,\n",
       "         -9.95622346e-03],\n",
       "        [-4.23291665e-03, -3.61552419e-03,  8.24586559e-05,\n",
       "          4.86474338e-03],\n",
       "        [-1.10361759e-02,  2.84817280e-03,  3.85703825e-03,\n",
       "          8.88826627e-03],\n",
       "        [-1.26777472e-02, -5.51307486e-03,  1.42452191e-02,\n",
       "          1.82450971e-02],\n",
       "        [ 1.78524498e-02,  1.04931918e-02, -7.17274008e-03,\n",
       "          1.64923102e-02]]),\n",
       " 'b2': array([[-0.00443235],\n",
       "        [-0.00351364],\n",
       "        [ 0.00568173],\n",
       "        [ 0.00067334],\n",
       "        [ 0.00176371]]),\n",
       " 'W3': array([[-0.00377855,  0.00651499, -0.00501368, -0.00362515,  0.01155414],\n",
       "        [-0.02147467,  0.00742642,  0.00193662, -0.0046015 ,  0.00130126],\n",
       "        [ 0.00021474, -0.01775818,  0.00506731, -0.00167902,  0.00225267],\n",
       "        [ 0.00218721, -0.00171325, -0.00721533, -0.01239023, -0.00325366],\n",
       "        [ 0.01236526, -0.00918283, -0.02128488,  0.01007956,  0.00023118]]),\n",
       " 'b3': array([[-0.01472561],\n",
       "        [ 0.00875291],\n",
       "        [ 0.0167706 ],\n",
       "        [ 0.00176469],\n",
       "        [ 0.00581545]]),\n",
       " 'W4': array([[-0.0020652 ,  0.01202024,  0.01211382,  0.00439426,  0.01601889]]),\n",
       " 'b4': array([[-0.00833491]])}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_list = [3,4,5,1]\n",
    "parameters = initialize_weights_deep(layer_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deep_forward(X, parameters):\n",
    "\n",
    "    no_weights = len(parameters)//2\n",
    "    A_temp = X\n",
    "    for l in range(1, no_weights):\n",
    "        z = np.dot(parameters[\"W\"+str(l)],A_temp)\n",
    "        a =  relu(z)\n",
    "        A_temp =a\n",
    "\n",
    "    Z = np.dot(parameters[\"W\"+str(no_weights)],A_temp)\n",
    "    a =  sigmoid(Z)\n",
    "     \n",
    "\n",
    "    A = sigmoid(A_temp)\n",
    "    return A\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_list = [3,4,5,6,7,8,9,1]\n",
    "parameters = initialize_weights_deep(layer_list)\n",
    "x = np.random.randn(3,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.7310585786300049)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep_forward(X=x, parameters=parameters)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cost Function is` mean square error`\n",
    "\n",
    "$$ \\text{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2 $$\n",
    "\n",
    "where:\n",
    "- $ n $ is the number of data points,\n",
    "- $ y_i $ is the actual value of the $i$-th data point,\n",
    "- $ \\hat{y}_i $ is the predicted value of the $i$-th data point.\n",
    "\n",
    "For a single datapoint (i.e., $ n = 1 $), the formula simplifies to:\n",
    "\n",
    "$$ \\text{MSE} = (y - \\hat{y})^2 $$\n",
    "\n",
    "where:\n",
    "- $ y $ is the actual value,\n",
    "- $ \\hat{y} $ is the predicted value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function(Y,AL):\n",
    "\n",
    "    # Y is the target\n",
    "    # AL is the predicted output\n",
    "\n",
    "    error = Y-AL\n",
    "\n",
    "    #we will use mean square error\n",
    "\n",
    "    cost = (1/2)*(error)**2\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class NeuralNetwork():\n",
    "#     def __init__(self,layer_list) -> None:\n",
    "#         self.layer_list = layer_list\n",
    "#         self.parameters = self.initialize_wights_deep(self.layer_list)\n",
    "\n",
    "#     def sigmoid(x):\n",
    "#         output = 1/(1+np.exp(-1))\n",
    "#         return output\n",
    "\n",
    "#     def relu(x):\n",
    "#         output = np.maximum(0,x)\n",
    "#         return output\n",
    "    \n",
    "#     def initialize_weights_deep(layer_list):\n",
    "#         #layer list contain the info of neural network\n",
    "#         #It can  be like [3,4,5,1]\n",
    "#         #this means input is 3, there are two hidden layers with 4 and 5 nodes respectively and 1 output\n",
    "        \n",
    "#         parameters = {}\n",
    "#         no_layers = len(layer_list)\n",
    "#         for l in range(1,no_layers):\n",
    "#             parameters[\"W\"+str(l)] = np.random.randn(layer_list[l], layer_list[l-1])*0.01\n",
    "#             parameters[\"b\"+str(l)] = np.random.randn(layer_list[l],1)*0.01\n",
    "            \n",
    "#         return parameters\n",
    "    \n",
    "#     def deep_forward(X, parameters):\n",
    "#         no_weights = len(parameters)//2\n",
    "#         A_temp = X\n",
    "#         for l in range(1, no_weights):\n",
    "#             z = np.dot(parameters[\"W\"+str(l)],A_temp)\n",
    "#             a =  relu(z)\n",
    "#             A_temp =a\n",
    "            \n",
    "#             Z = np.dot(parameters[\"W\"+str(no_weights)],A_temp)\n",
    "#             a =  sigmoid(Z)\n",
    "\n",
    "#         A = sigmoid(A_temp)\n",
    "#         return A\n",
    "    \n",
    "#     def cost_function(Y,AL):\n",
    "#         # Y is the target\n",
    "#         # AL is the predicted output\n",
    "#         error = Y-AL\n",
    "#         #we will use mean square error\n",
    "#         cost = (1/2)*(error)**2\n",
    "#         return cost\n",
    "\n",
    "\n",
    "\n",
    "class NeuralNetwork():\n",
    "    def __init__(self,layer_list = [1,3,1]) -> None:\n",
    "        self.layer_list = layer_list\n",
    "        self.parameters = self.initialize_wights_deep(self.layer_list)\n",
    "\n",
    "    def sigmoid(self,x):\n",
    "        output = 1 / (1 + np.exp(-x))\n",
    "        return output  \n",
    "        \n",
    "    def relu(self,x):\n",
    "        output = np.maximum(0,x)\n",
    "        return output\n",
    "    \n",
    "    def initialize_wights_deep(self,layer_list):\n",
    "        parameters = {}\n",
    "        no_layers = len(layer_list)\n",
    "\n",
    "        for l in range(1, no_layers) :\n",
    "            parameters[\"W\" + str(l)] = np.random.randn(layer_list[l],layer_list[l-1]) * 0.01\n",
    "            parameters[\"b\" + str(l)] = np.random.randn(layer_list[l],1) * 0.01\n",
    "            \n",
    "        return parameters\n",
    "\n",
    "    def deep_forward(self,X):\n",
    "        no_weights = len(self.parameters)//2\n",
    "        A_temp = X\n",
    "        for l in range(1,no_weights):\n",
    "            z = np.dot(self.parameters[\"W\" + str(l)], A_temp) \n",
    "            a = self.relu(z)\n",
    "            A_temp = a\n",
    "        \n",
    "        Z = np.dot(self.parameters[\"W\" + str(no_weights)], A_temp)\n",
    "        A = self.sigmoid(Z)\n",
    "        return A\n",
    "\n",
    "    def cost_function(self,Y, AL) :\n",
    "        # Y is the target\n",
    "        # AL is the predicted output\n",
    "        error = Y - AL\n",
    "        # we will use mean square error\n",
    "        cost = (1/2) * (error)**2\n",
    "        return cost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetwork(layer_list=[3,4,5,6,7,8,9,1])\n",
    "\n",
    "X = np.random.randn(3,1)\n",
    "\n",
    "AL = model.deep_forward(X=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.125]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cost_function(Y=1 , AL= AL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "apeksha",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
